syntax = "proto3";

package neuro_pipeline;

option java_multiple_files = true;
option java_package = "com.neuropipeline.proto";

// =============================================================================
// Service Definition
// =============================================================================

// Core service for edge-cloud communication.
service NeuroPipelineService {
  // Edge streams detection results to central (Client Streaming)
  rpc StreamDetectionResults(stream DetectionResult) returns (StreamResponse);

  // Central sends control commands to edge (Unary)
  rpc SendControlCommand(ControlCommand) returns (CommandResponse);

  // Bidirectional event streaming
  rpc BidirectionalEventStream(stream EdgeEvent) returns (stream CentralEvent);

  // Health check
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);

  // Edge device registration
  rpc RegisterDevice(DeviceRegistration) returns (DeviceRegistrationResponse);

  // v2: Model lifecycle management (deploy/undeploy/list/rollback)
  rpc ManageModel(ModelManagementRequest) returns (ModelManagementResponse);

  // v2: Query time-series metrics
  rpc QueryTimeSeries(TimeSeriesQuery) returns (TimeSeriesResponse);
}

// =============================================================================
// Detection Messages
// =============================================================================

// Object detection result from edge NPU inference.
message DetectionResult {
  uint64 frame_id = 1;             // Unique frame identifier (monotonic)
  uint64 timestamp_us = 2;         // Microseconds since epoch (monotonic clock)
  repeated BoundingBox boxes = 3;  // Detected objects
  bytes frame_data = 4;            // Optional JPEG-encoded frame (sent on events)
  DeviceMetrics metrics = 5;       // System performance metrics
  string trace_id = 6;             // Distributed trace identifier
  string device_id = 7;            // Source edge device identifier
  string span_id = 8;              // Distributed tracing span identifier

  // v2 extensions (high field numbers for backward compat)
  string model_id = 100;                  // Which model produced these detections
  repeated float feature_vector = 101;    // Frame-level embedding for ReID/similarity
}

// Single detected object bounding box.
message BoundingBox {
  uint32 class_id = 1;     // COCO dataset class ID
  string class_name = 2;   // Human-readable class label
  float confidence = 3;    // Detection confidence [0.0, 1.0]

  // Normalized coordinates [0.0, 1.0] relative to frame width/height
  float x_min = 4;
  float y_min = 5;
  float x_max = 6;
  float y_max = 7;

  // v2 extensions
  uint64 track_id = 100;   // Object tracking ID (assigned by TemporalTracker)
}

// Device performance metrics.
message DeviceMetrics {
  float cpu_usage = 1;       // CPU usage percentage [0.0, 100.0]
  float npu_usage = 2;       // NPU usage percentage [0.0, 100.0]
  float memory_used_mb = 3;  // Memory usage in MB
  float temperature_c = 4;   // Device temperature in Celsius
  uint32 fps = 5;            // Current processing frame rate
}

// Response to streaming detection results.
message StreamResponse {
  bool success = 1;
  string message = 2;
  uint64 frames_received = 3;
}

// =============================================================================
// Control Messages
// =============================================================================

// Command from central to edge device.
message ControlCommand {
  enum CommandType {
    SET_FPS = 0;                   // Adjust camera frame rate
    CHANGE_MODEL = 1;              // Switch AI model
    ENABLE_DEBUG = 2;              // Toggle debug logging
    SET_DETECTION_THRESHOLD = 3;   // Adjust confidence threshold
    SHUTDOWN = 4;                  // Graceful shutdown
    RELOAD_MODEL = 5;              // Hot-reload current model
    SWITCH_MODEL_VARIANT = 6;      // v2: Switch to a specific model variant by ID
    SET_DETECTION_REGION = 7;      // v2: Update detection ROI (VLM-guided)
    SET_SENSITIVITY = 8;           // v2: Adjust detection sensitivity (VLM-guided)
  }

  CommandType type = 1;
  map<string, string> parameters = 2;   // Command-specific parameters
  uint64 command_id = 3;                // Unique command identifier
}

// Response to a control command.
message CommandResponse {
  bool success = 1;
  string message = 2;
  uint64 command_id = 3;   // Echo back command_id for correlation
}

// =============================================================================
// Event Messages
// =============================================================================

// Event from edge to central.
message EdgeEvent {
  enum EventType {
    DETECTION_ALERT = 0;    // Critical detection (e.g., person in restricted area)
    SYSTEM_ERROR = 1;       // System-level error
    MODEL_LOADED = 2;       // Model successfully loaded
    HEALTH_UPDATE = 3;      // Periodic health heartbeat
  }

  EventType type = 1;
  uint64 timestamp_us = 2;
  string description = 3;
  map<string, string> metadata = 4;   // Event-specific key-value data
}

// Event from central to edge.
message CentralEvent {
  enum EventType {
    COMMAND_ACK = 0;         // Acknowledge received command
    INFERENCE_RESULT = 1;    // VLM inference result
    ALERT = 2;               // Alert from central analysis
    CONTROL_COMMAND = 3;     // Control command forwarded via event stream
  }

  EventType type = 1;
  uint64 timestamp_us = 2;
  string payload = 3;       // JSON or plain text payload
  ControlCommand command = 5;  // Populated when type == CONTROL_COMMAND
}

// =============================================================================
// Health Check
// =============================================================================

message HealthCheckRequest {
  string client_id = 1;
}

message HealthCheckResponse {
  enum Status {
    SERVING = 0;
    NOT_SERVING = 1;
    UNKNOWN = 2;
  }

  Status status = 1;
  string version = 2;
}

// =============================================================================
// Video Frame (for streaming)
// =============================================================================

// Raw or compressed video frame.
message VideoFrame {
  uint64 frame_id = 1;
  uint64 timestamp_us = 2;
  uint32 width = 3;
  uint32 height = 4;

  enum PixelFormat {
    RGB888 = 0;
    NV12 = 1;
    JPEG = 2;
  }

  PixelFormat format = 5;
  bytes data = 6;            // Raw or compressed frame data
}

// =============================================================================
// Error Reporting
// =============================================================================

// Structured error report for diagnostics.
message ErrorReport {
  string error_code = 1;     // Machine-readable error code (e.g., "INFERENCE_FAILED")
  string message = 2;        // Human-readable description
  string component = 3;      // Source component (e.g., "rknn_engine", "grpc_client")
  uint64 timestamp_us = 4;   // When the error occurred
  string trace_id = 5;       // Correlation with detection trace
}

// =============================================================================
// Device Registration
// =============================================================================

// Edge device registration request.
message DeviceRegistration {
  string device_id = 1;          // Unique device identifier
  string device_name = 2;        // Human-readable name
  string firmware_version = 3;   // Edge software version
  repeated string capabilities = 4;  // e.g. ["npu", "camera", "gpu"]
  DeviceMetrics initial_metrics = 5; // Metrics at registration time
}

// Response to device registration.
message DeviceRegistrationResponse {
  bool success = 1;
  string message = 2;
  string assigned_id = 3;        // Server-assigned ID (or echo back device_id)
}

// =============================================================================
// v2: Model Management
// =============================================================================

// Describes a deployable model.
message ModelInfo {
  string model_id = 1;            // Unique model identifier (e.g., "yolov5s-640")
  string model_path = 2;          // Path on device or registry
  string model_type = 3;          // "detection", "classification", "reid", etc.
  string version = 4;             // Semantic version string
  map<string, string> metadata = 5;  // Arbitrary metadata (accuracy, size, etc.)
}

// Model management request.
message ModelManagementRequest {
  enum Action {
    DEPLOY = 0;       // Deploy a model to edge device(s)
    UNDEPLOY = 1;     // Remove a model from edge device(s)
    LIST = 2;         // List deployed models
    ROLLBACK = 3;     // Rollback to previous model version
    STATUS = 4;       // Get model deployment status
  }

  Action action = 1;
  ModelInfo model = 2;             // Model to deploy/undeploy (ignored for LIST)
  string target_device_id = 3;    // Target device ("" = all devices)
  int32 npu_core = 4;             // Target NPU core (0-2, -1 = auto)
}

// Model management response.
message ModelManagementResponse {
  bool success = 1;
  string message = 2;
  repeated ModelInfo models = 3;   // Populated for LIST action
}

// =============================================================================
// v2: Behavior Alert
// =============================================================================

// Behavior alert from temporal analysis.
message BehaviorAlert {
  string device_id = 1;
  uint64 timestamp_us = 2;
  string behavior_type = 3;       // "loitering", "running", "lingering", "crowd"
  float severity = 4;             // [0.0, 1.0]
  uint64 track_id = 5;            // Associated tracked object
  string description = 6;
  map<string, string> metadata = 7;
}

// =============================================================================
// v2: Time Series Query
// =============================================================================

// Single time-series data point.
message TimeSeriesPoint {
  double timestamp = 1;           // Unix timestamp (seconds)
  double value = 2;
  map<string, string> labels = 3; // Optional labels
}

// Time-series query request.
message TimeSeriesQuery {
  string metric_name = 1;         // e.g., "detections_count", "fps", "latency"
  string device_id = 2;           // Filter by device ("" = all)
  double start_time = 3;          // Unix timestamp
  double end_time = 4;            // Unix timestamp (0 = now)
  string aggregation = 5;         // "avg", "sum", "max", "min", "count"
  int32 bucket_seconds = 6;       // Aggregation bucket size (0 = raw)
}

// Time-series query response.
message TimeSeriesResponse {
  bool success = 1;
  string message = 2;
  repeated TimeSeriesPoint points = 3;
}
